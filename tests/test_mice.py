import numpy as np
import pandas as pd
import mice
import statsmodels.api as sm

def load_data():
    """
    Load a data set from the results directory, generated by R mice routine.
    """

    params = pd.io.parsers.read_csv("params.csv")
    params.columns = ['int', 'x2', 'x3']
    cov = pd.io.parsers.read_csv("cov.csv")
    cov.columns = ['int', 'x2', 'x3']
    data = pd.io.parsers.read_csv("missingdata.csv")
    data.columns = ['x1', 'x2', 'x3']

    return params,cov,data

class TestMice(object):
    def __init__(self):
        self.formula = "X2~X3+X4"

    def test_get_data_from_formula(self):
        np.random.seed(1325)
        data = np.random.normal(size=(10,4))
        data[8:, 1] = np.nan
        df = pd.DataFrame(data, columns=["X1", "X2", "X3", "X4"])
        imp_dat = mice.ImputedData(df)
        endog_obs, exog_obs, exog_miss = imp_dat.get_data_from_formula(
                                                            self.formula)
        endog_obs, exog_obs, exog_miss = imp_dat.get_data_from_formula(
                                                            self.formula)
        endog_obs = np.asarray(endog_obs).flatten()
        exog_obs = np.asarray(exog_obs)[:,1:]
        exog_miss = np.asarray(exog_miss)[:,1:]
        test_exog_obs = data[0:8,2:]
        test_exog_miss = data[-2:,2:]
        test_endog_obs = data[0:8,1]
        np.testing.assert_almost_equal(exog_obs, test_exog_obs)
        np.testing.assert_almost_equal(exog_miss, test_exog_miss)
        np.testing.assert_almost_equal(endog_obs, test_endog_obs)

    def test_store_changes(self):
        np.random.seed(1325)
        data = np.random.normal(size=(10,4))
        data[8:, 1] = np.nan
        df = pd.DataFrame(data, columns=["X1", "X2", "X3", "X4"])
        imp_dat = mice.ImputedData(df)
        imp_dat.store_changes("X2", [0] * 2)
        test_data = np.asarray(imp_dat.data["X2"][8:])
        np.testing.assert_almost_equal(test_data, np.asarray([0., 0.]))
        
    def test_perturb_params(self):
        np.random.seed(1325)
        data = np.random.normal(size=(10,4))
        data[8:, 1] = np.nan
        df = pd.DataFrame(data, columns=["X1", "X2", "X3", "X4"])
        params_test = np.asarray([-0.06523173,  0.37082165, -0.68803828])
        scale_test = 1.0
        md = sm.OLS.from_formula(self.formula, df)
        mdf = md.fit()
        imputer = mice.Imputer(self.formula, sm.OLS, mice.ImputedData(df))
        params, scale_per = imputer.perturb_params(mdf)
        params = np.asarray(params)
        np.testing.assert_almost_equal(params, params_test)
        np.testing.assert_almost_equal(scale_per, scale_test)

    def test_impute_asymptotic_bayes(self):
        np.random.seed(1325)
        data = np.random.normal(size=(10,4))
        data[8:, 1] = np.nan
        df = pd.DataFrame(data, columns=["X1", "X2", "X3", "X4"])
        imputer = mice.Imputer(self.formula, sm.OLS, mice.ImputedData(df))
        imputer.impute_asymptotic_bayes()
        np.testing.assert_almost_equal(np.asarray(imputer.data.data['X2'][8:]),
                                       np.asarray([-0.64163604, -0.26610016]))

    def test_impute_pmm(self):
        np.random.seed(1325)
        data = np.random.normal(size=(10,4))
        data[8:, 1] = np.nan
        df = pd.DataFrame(data, columns=["X1", "X2", "X3", "X4"])
        imputer = mice.Imputer(self.formula, sm.OLS, mice.ImputedData(df))
        imputer.impute_pmm()
        np.testing.assert_almost_equal(np.asarray(imputer.data.data['X2'][8:]),
                                       np.asarray([ 0.50272064,  0.68366113]))

    def test_combine(self):
        np.random.seed(1325)
        data = np.random.normal(size=(10,4))
        data[8:, 1] = np.nan
        df = pd.DataFrame(data, columns=["X1", "X2", "X3", "X4"])
        impdata = mice.ImputedData(df)
        impdata.new_imputer("X2", scale_method="perturb_chi2", method="pmm",
                                k_pmm=20)
        impcomb = mice.MICE("X2 ~ X1 + X3", sm.OLS, impdata)
        impcomb.run()
        p1 = impcomb.combine()
        np.testing.assert_almost_equal(p1.params, np.asarray([0.38021906, 
                                                              -0.0572892 , 
                                                              -0.13245096 ]))
        np.testing.assert_almost_equal(p1.scale, 0.44794708586717524)
        np.testing.assert_almost_equal(p1.cov_params(), np.asarray([
        [ 0.05769299,  0.02021915, -0.00322985],
        [ 0.02021915,  0.05233605, -0.00184258],
        [-0.00322985, -0.00184258,  0.05320861]]))

    def test_nomissing(self):
    
        n, p = 100, 5
        data = np.random.normal(size=(n, p))
        data[:,-1] = data.sum(1)
        data = pd.DataFrame(data, columns=["X1", "X2", "X3", "X4", "Y"])

        imp_data = mice.ImputedData(data)
        for name in data.columns:
            imp_data.new_imputer(name)
        mice_mod = mice.MICE("Y ~ X1 + X2 + X3 + X4", sm.OLS, imp_data)
        mice_mod.run()
        mice_rslt = mice_mod.combine()

        ols_mod = sm.OLS.from_formula("Y ~ X1 + X2 + X3 + X4", data)
        ols_rslt = ols_mod.fit()

        np.testing.assert_almost_equal(mice_rslt.params,
                                       np.asarray(ols_rslt.params))
        np.testing.assert_almost_equal(mice_rslt.cov_params(),
                                       np.asarray(ols_rslt.cov_params()))
        np.testing.assert_almost_equal(mice_rslt.bse, np.asarray(ols_rslt.bse))
        
    def test_overall(self):
        """
        R code used for comparison:

        require(mvtnorm)
        size = 1000
        cor = 0.9
        mu = rep(0,3)
        sig = matrix(cor, nrow=3, ncol=3) + diag(3) * (1-cor) #Generate covariance matrix for normal
        draws = rmvnorm(n=size, mean=mu, sigma=sig)
        unidraws = pnorm(draws) #Apply probability integral transform to get uniform draws
        normdraws1 = draws[,1] #Draw from original normal
        berndraws = qbinom(1-unidraws[,2], 1, 0.75) #Inverse Bernoulli cdf using uniform draws
        normdraws2 = draws[,3] #Inverse Poisson cdf using uniform draws
        y<--1+1*berndraws-1*normdraws1+1*normdraws2+rnorm(size,0,1) #Simulate linear regression to get conditional behavior in missingness rate
        
        alpha.1<-exp(-1+2*y-normdraws1)/(1+exp(-1+2*y-normdraws1))
        alpha.2<-exp(-3.5+.7*y)/(1+exp(-3.5+.7*y))
        alpha.3<-exp(-6+1.2*y-berndraws)/(1+exp(-6+1.2*y-berndraws))
                
        r.berndraws.mar<-rbinom(size,1,prob=alpha.1)
        r.normdraws1.mar<-rbinom(size,1,prob=alpha.2)
        r.normdraws2.mar<-rbinom(size,1,prob=alpha.3)
        berndraws.mar<-berndraws*(1-r.berndraws.mar)+r.berndraws.mar*99999  #berndraws.mar=berndraws if not missing, 99999 if missing
        normdraws1.mar<-normdraws1*(1-r.normdraws1.mar)+r.normdraws1.mar*99999
        normdraws2.mar<-normdraws2*(1-r.normdraws2.mar)+r.normdraws2.mar*99999
        berndraws.mar[berndraws.mar==99999]=NA #change 99999 to NA (R's notation for missing)
        normdraws1.mar[normdraws1.mar==99999]=NA
        normdraws2.mar[normdraws2.mar==99999]=NA
        
        require(mice)
        data = as.data.frame(cbind(berndraws.mar,normdraws1.mar,normdraws2.mar))
        data$berndraws.mar = as.factor(data$berndraws.mar)
        params = array(0, nrep)
        imp_pmm = mice(data, m=10, maxit=20, method="pmm")
        fit = with(data=imp_pmm,exp=glm(berndraws.mar~normdraws1.mar + normdraws2.mar,family=binomial))   
        pooled = pool(fit)
        print(summary(pooled))
        setwd("C:/Users/Frank/Documents/GitHub/statsmodels/statsmodels/sandbox/mice/tests")
        write.csv(cbind(pooled$u[1:20], pooled$u[81:100], pooled$u[161:180]), "cov.csv", row.names=FALSE)
        write.csv(pooled$qhat, "params.csv", row.names=FALSE)
        write.csv(data, "missingdata.csv", row.names=FALSE)
        """
        params,cov,data = load_data()
        r_pooled_se = np.sqrt(np.asarray(np.mean(cov) + (1 + 1 / 20.) * np.var(params)))
        r_pooled_params = np.asarray(np.mean(params))
        impdata = mice.ImputedData(data)
        impdata.new_imputer("x2", method="pmm", k_pmm=20)
        impdata.new_imputer("x3", method="pmm", k_pmm=20)
        impdata.new_imputer("x1", model_class=sm.Logit, method="pmm", k_pmm=20)
        impcomb = mice.MICE("x1 ~ x2 + x3", sm.Logit, impdata)
        impcomb.run(20,10)
        p1 = impcomb.combine()
        print p1.summary()        
        np.testing.assert_allclose(p1.params, r_pooled_params, rtol=0.1)
        np.testing.assert_allclose(np.sqrt(np.diag(p1.cov_params())), r_pooled_se, rtol=0.1)

if  __name__=="__main__":

    import nose

    nose.runmodule(argv=[__file__,'-vvs','-x','--pdb', '--pdb-failure'],
                   exit=False)
